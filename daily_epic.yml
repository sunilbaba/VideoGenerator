import os
import json
import random
import asyncio
import requests
import textwrap
from datetime import datetime

# --- MOVIEPY & PILLOW FIX ---
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

import google.generativeai as genai
import edge_tts
from moviepy.editor import *

# --- CONFIGURATION ---
# Reads from GitHub Secrets first, falls back to local string for testing
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyDw8GuHo9kKc6ttnOfM4FpYP7xhKcPAR_U")

OUTPUT_FOLDER = "rendered_episodes"
STATE_FILE = "story_history.json"
RESOLUTION = (1080, 1920)

CHARACTER_PROMPTS = {
    "Arjuna": "Arjuna the warrior prince, handsome indian man, golden celestial armor, holding the Gandiva bow, divine glow, ancient vedic clothing",
    "Krishna": "Lord Krishna, blue skin, peacock feather in crown, yellow silk robes, serene smile, playing flute, divine aura",
    "Draupadi": "Draupadi, most beautiful indian queen, dark skin, elegant saree with gold embroidery, determined eyes, royal jewelry",
    "Bhishma": "Bhishma Pitamah, old wise warrior, white long beard, silver armor, stern expression, standing on a battlefield",
    "Karna": "Karna, warrior with golden earrings and attached chest armor, sun glowing behind him, tragic hero look"
}

genai.configure(api_key=GEMINI_API_KEY)

def get_next_story_segment():
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, 'r') as f:
            history = json.load(f)
    else:
        history = {"last_summary": "The epic tale begins.", "episode_count": 0}

    episode_num = history['episode_count'] + 1
    print(f"[*] Generating Script for Episode {episode_num}...")

    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    prompt = f"""
    You are the narrator of the Mahabharata. 
    Previous Context: {history['last_summary']}
    Task: Write the NEXT continuous part of the story (30 seconds).
    JSON Structure: {{ "script": "...", "image_prompt": "...", "summary": "..." }}
    """
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        data = json.loads(response.text)
        history['last_summary'] = data['summary']
        history['episode_count'] = episode_num
        return data, history
    except Exception as e:
        print(f"AI Error: {e}")
        return None, None

def enhance_visuals(base_prompt, script):
    final_prompt = base_prompt
    for name, desc in CHARACTER_PROMPTS.items():
        if name in script or name in base_prompt:
            final_prompt += f", featuring {desc}"
    return final_prompt + ", cinematic lighting, 8k, photorealistic, flux model style"

def generate_image(prompt, filename):
    print(f"[*] Generating Image...")
    try:
        encoded_prompt = requests.utils.quote(prompt)
        seed = random.randint(1, 999999)
        url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width={RESOLUTION[0]}&height={RESOLUTION[1]}&seed={seed}&model=flux&nologo=true"
        resp = requests.get(url, timeout=60)
        if resp.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(resp.content)
            return True
    except Exception as e:
        print(f"Image Error: {e}")
    return False

async def generate_audio(text, filename):
    print(f"[*] Synthesizing Audio...")
    communicate = edge_tts.Communicate(text, "en-IN-PrabhatNeural", pitch='-2Hz', rate='-5%')
    await communicate.save(filename)

def create_motion_video(image_path, audio_path, output_path):
    print("[*] Rendering Video...")
    try:
        audio_clip = AudioFileClip(audio_path)
        img_clip = ImageClip(image_path).set_duration(audio_clip.duration + 0.5)
        
        # Pan Effect
        img_clip = img_clip.resize(height=int(RESOLUTION[1] * 1.2))
        img_clip = img_clip.set_position(lambda t: ('center', -10 - (t * 30)))
        
        final_clip = CompositeVideoClip([img_clip], size=RESOLUTION).set_audio(audio_clip)
        final_clip.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac')
        return True
    except Exception as e:
        print(f"Render Error: {e}")
        return False

def main():
    if not os.path.exists(OUTPUT_FOLDER): os.makedirs(OUTPUT_FOLDER)
    
    story_data, new_history = get_next_story_segment()
    if not story_data: return

    script = story_data['script']
    episode_num = new_history['episode_count']
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    temp_img = "temp_visual.jpg"
    temp_audio = "temp_audio.mp3"
    final_video = f"{OUTPUT_FOLDER}/Ep{episode_num}_Mahabharata_{timestamp}.mp4"
    
    if generate_image(enhance_visuals(story_data['image_prompt'], script), temp_img):
        asyncio.run(generate_audio(script, temp_audio))
        if create_motion_video(temp_img, temp_audio, final_video):
            print(f"[SUCCESS] Video Saved: {final_video}")
            with open(STATE_FILE, 'w') as f:
                json.dump(new_history, f, indent=4)

    if os.path.exists(temp_img): os.remove(temp_img)
    if os.path.exists(temp_audio): os.remove(temp_audio)

if __name__ == "__main__":
    main()
